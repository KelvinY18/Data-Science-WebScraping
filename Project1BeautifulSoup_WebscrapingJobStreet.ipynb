{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOVbdPU1cANgxCD9J4x4deJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KelvinY18/Data-Science-WebScraping/blob/main/Project1BeautifulSoup_WebscrapingJobStreet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lolwz7U-93I6"
      },
      "source": [
        "# WEB SCRAPPING for JOBSTREET\n",
        "\n",
        "import csv\n",
        "from datetime import datetime\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "# generating url for postion and location\n",
        "def get_url(position,location):\n",
        "    position = position.replace(' ','-')\n",
        "    location = location.replace(' ','-')\n",
        "    template = 'https://www.jobstreet.com.my/en/job-search/{}-jobs-in-{}/'\n",
        "    url = template.format(position,location)\n",
        "    return url\n",
        "\n",
        "def get_job(card):\n",
        "    # job name\n",
        "    try:\n",
        "        job_name = card.find('div','sx2jih0 _2j8fZ_0 sIMFL_0 _1JtWu_0').text.strip()\n",
        "    except:\n",
        "        job_name = ''\n",
        "\n",
        "    # job url\n",
        "    try:\n",
        "        anchor_tag = card.a\n",
        "        job_url = 'https://www.jobstreet.com.my'+anchor_tag.get('href')\n",
        "    except:\n",
        "        job_url = ''\n",
        "\n",
        "    # company name\n",
        "    try:\n",
        "        company_name = card.find('span','sx2jih0 zcydq82b _18qlyvc0 _18qlyvcv _18qlyvc1 _18qlyvc8').text.strip()\n",
        "    except:\n",
        "        company_name = ''\n",
        "\n",
        "    # job location\n",
        "    try:\n",
        "        job_location = card.find('span','sx2jih0 zcydq82b zcydq8r iwjz4h0').text.strip()\n",
        "    except:\n",
        "        job_location = ''\n",
        "\n",
        "    # fetching job summary\n",
        "    try:\n",
        "     summary = ''\n",
        "     tag_str = ''\n",
        "     job_summary = card.find('ul','sx2jih0 sx2jih3 h6p8rp0 h6p8rp5')\n",
        "     for tag in job_summary(\"li\"):\n",
        "        tag_str = tag.text\n",
        "        summary += tag_str + ','\n",
        "        summary = summary.rstrip(',')\n",
        "    except AttributeError:\n",
        "     summary = ''\n",
        "\n",
        "    # fetching job salary\n",
        "    job_salary = card.find_all('span', 'sx2jih0 zcydq82b _18qlyvc0 _18qlyvcv _18qlyvc3 _18qlyvc6')\n",
        "\n",
        "    try:\n",
        "     if len(job_salary) >= 2:\n",
        "        job_salary = job_salary[1]\n",
        "        salary = job_salary.text.strip()\n",
        "     else:\n",
        "        salary = ''\n",
        "    except IndexError:\n",
        "     salary = ''\n",
        "\n",
        "    # fetch date\n",
        "    time_tag = card.time\n",
        "    post_date = time_tag.get('datetime')\n",
        "    post_date = post_date.split(\"T\", 1)\n",
        "    post_date = post_date[0]\n",
        "    today = datetime.today().strftime('%Y-%m-%d')\n",
        "\n",
        "    job_info = (job_name,job_url,company_name,job_location,summary,salary,post_date,today)\n",
        "\n",
        "\n",
        "    return job_info\n",
        "\n",
        "def main(position,location):\n",
        "    records = []\n",
        "    url = get_url(position,location)\n",
        "\n",
        "    response = requests.get(url)\n",
        "\n",
        "    soup = BeautifulSoup(response.text,'html.parser')\n",
        "\n",
        "    cards = soup.find_all('div','sx2jih0 zcydq85k zcydq84t zcydq83t zcydq842')\n",
        "\n",
        "\n",
        "    for everyCard in cards:\n",
        "        jobDetails = get_job(everyCard)\n",
        "        records.append(jobDetails)\n",
        "\n",
        "\n",
        "\n",
        "    # here we are using panda Data frame to save jobs in a csv file\n",
        "\n",
        "    col = ['JobName','JobUrl','CompanyName','JobLocation','JobSummary','JobSalary','PostDate','Today']\n",
        "\n",
        "    JobStreet_data = pd.DataFrame(records,columns=col)\n",
        "\n",
        "    JobStreet_data.to_csv('D:\\\\JobStreetData.csv',encoding='utf-8')\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3aZ7Bda-bZo"
      },
      "source": [
        "main('Python developer','Selangor')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}